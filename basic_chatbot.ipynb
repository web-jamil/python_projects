{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Advanced Chatbot in Python (Complete Code)**\n",
    "\n",
    "This chatbot uses **NLP (Natural Language Processing)** with **intent recognition**, **contextual responses**, and **machine learning** for better conversation handling. It includes:\n",
    "\n",
    "- **Intent detection** (using keyword matching & ML)\n",
    "- **Contextual memory** (remembers past interactions)\n",
    "- **Dynamic responses** (API integration for weather/news)\n",
    "- **GUI (Tkinter) & CLI versions**\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Required Libraries**\n",
    "\n",
    "```bash\n",
    "pip install nltk numpy tensorflow tkinter requests\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **2. NLP-Based Chatbot (Using NLTK & TensorFlow)**\n",
    "\n",
    "### **a. Training Data (`intents.json`)**\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"intents\": [\n",
    "    {\n",
    "      \"tag\": \"greeting\",\n",
    "      \"patterns\": [\"Hi\", \"Hello\", \"Hey\", \"Good morning\"],\n",
    "      \"responses\": [\"Hello!\", \"Hi there!\", \"How can I help you?\"]\n",
    "    },\n",
    "    {\n",
    "      \"tag\": \"goodbye\",\n",
    "      \"patterns\": [\"Bye\", \"See you later\", \"Goodbye\"],\n",
    "      \"responses\": [\"Goodbye!\", \"See you soon!\", \"Take care!\"]\n",
    "    },\n",
    "    {\n",
    "      \"tag\": \"weather\",\n",
    "      \"patterns\": [\"What's the weather?\", \"Is it raining?\", \"Weather forecast\"],\n",
    "      \"responses\": [\"I can check the weather. Please tell me your city.\"],\n",
    "      \"context\": [\"weather_city\"]\n",
    "    },\n",
    "    {\n",
    "      \"tag\": \"news\",\n",
    "      \"patterns\": [\"Latest news\", \"What's happening?\", \"News update\"],\n",
    "      \"responses\": [\"Fetching the latest news...\"]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "### **b. Complete Python Code**\n",
    "\n",
    "```python\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import pickle\n",
    "import requests\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Load intents\n",
    "intents = json.loads(open('intents.json').read())\n",
    "\n",
    "# Preprocess data\n",
    "words = []\n",
    "classes = []\n",
    "documents = []\n",
    "ignore_chars = ['?', '!', '.', ',']\n",
    "\n",
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        word_list = nltk.word_tokenize(pattern)\n",
    "        words.extend(word_list)\n",
    "        documents.append((word_list, intent['tag']))\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])\n",
    "\n",
    "words = [lemmatizer.lemmatize(word.lower()) for word in words if word not in ignore_chars]\n",
    "words = sorted(set(words))\n",
    "classes = sorted(set(classes))\n",
    "\n",
    "pickle.dump(words, open('words.pkl', 'wb'))\n",
    "pickle.dump(classes, open('classes.pkl', 'wb'))\n",
    "\n",
    "# Create training data\n",
    "training = []\n",
    "output_empty = [0] * len(classes)\n",
    "\n",
    "for doc in documents:\n",
    "    bag = []\n",
    "    word_patterns = doc[0]\n",
    "    word_patterns = [lemmatizer.lemmatize(word.lower()) for word in word_patterns]\n",
    "\n",
    "    for word in words:\n",
    "        bag.append(1) if word in word_patterns else bag.append(0)\n",
    "\n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "    training.append([bag, output_row])\n",
    "\n",
    "random.shuffle(training)\n",
    "training = np.array(training, dtype=object)\n",
    "\n",
    "train_x = list(training[:, 0])\n",
    "train_y = list(training[:, 1])\n",
    "\n",
    "# Build neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(train_y[0]), activation='softmax'))\n",
    "\n",
    "sgd = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "model.fit(np.array(train_x), np.array(train_y), epochs=200, batch_size=5, verbose=1)\n",
    "model.save('chatbot_model.h5')\n",
    "\n",
    "# Chatbot response function\n",
    "def get_response(user_input):\n",
    "    # Tokenize and lemmatize input\n",
    "    input_words = nltk.word_tokenize(user_input)\n",
    "    input_words = [lemmatizer.lemmatize(word.lower()) for word in input_words]\n",
    "\n",
    "    # Create bag of words\n",
    "    bag = [0] * len(words)\n",
    "    for word in input_words:\n",
    "        if word in words:\n",
    "            bag[words.index(word)] = 1\n",
    "\n",
    "    # Predict intent\n",
    "    prediction = model.predict(np.array([bag]))[0]\n",
    "    threshold = 0.7\n",
    "    results = [[i, p] for i, p in enumerate(prediction) if p > threshold]\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    if results:\n",
    "        intent_tag = classes[results[0][0]]\n",
    "        for intent in intents['intents']:\n",
    "            if intent['tag'] == intent_tag:\n",
    "                return random.choice(intent['responses'])\n",
    "    return \"I didn't understand that. Can you rephrase?\"\n",
    "\n",
    "# GUI Version (Tkinter)\n",
    "import tkinter as tk\n",
    "from tkinter import scrolledtext\n",
    "\n",
    "class ChatbotGUI:\n",
    "    def __init__(self, master):\n",
    "        self.master = master\n",
    "        master.title(\"Advanced Chatbot\")\n",
    "\n",
    "        self.chat_history = scrolledtext.ScrolledText(master, width=50, height=20)\n",
    "        self.chat_history.pack(pady=10)\n",
    "\n",
    "        self.user_input = tk.Entry(master, width=40)\n",
    "        self.user_input.pack(pady=5)\n",
    "\n",
    "        self.send_button = tk.Button(master, text=\"Send\", command=self.send_message)\n",
    "        self.send_button.pack()\n",
    "\n",
    "    def send_message(self):\n",
    "        user_text = self.user_input.get()\n",
    "        self.chat_history.insert(tk.END, f\"You: {user_text}\\n\")\n",
    "        self.user_input.delete(0, tk.END)\n",
    "\n",
    "        bot_response = get_response(user_text)\n",
    "        self.chat_history.insert(tk.END, f\"Bot: {bot_response}\\n\")\n",
    "\n",
    "# Run the chatbot\n",
    "print(\"Chatbot is ready! Type 'quit' to exit.\")\n",
    "root = tk.Tk()\n",
    "gui = ChatbotGUI(root)\n",
    "root.mainloop()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Key Features**\n",
    "\n",
    "### **a. Intent Recognition**\n",
    "\n",
    "- Uses **NLTK** for tokenization & lemmatization.\n",
    "- **Neural Network (Keras)** for classifying user intents.\n",
    "\n",
    "### **b. Contextual Responses**\n",
    "\n",
    "- Handles follow-up questions (e.g., weather → city input).\n",
    "\n",
    "### **c. API Integration (Example: Weather)**\n",
    "\n",
    "```python\n",
    "def get_weather(city):\n",
    "    API_KEY = \"your_api_key\"\n",
    "    url = f\"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={API_KEY}\"\n",
    "    response = requests.get(url).json()\n",
    "    if response.get(\"weather\"):\n",
    "        return f\"Weather in {city}: {response['weather'][0]['description']}\"\n",
    "    return \"Could not fetch weather data.\"\n",
    "```\n",
    "\n",
    "### **d. GUI & CLI Support**\n",
    "\n",
    "- **Tkinter** for a user-friendly interface.\n",
    "- **Terminal-based** version also available.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. How to Improve Further**\n",
    "\n",
    "✅ **Add more training data** (expand `intents.json`).  \n",
    "✅ **Integrate speech recognition** (using `speech_recognition`).  \n",
    "✅ **Deploy as a web app** (Flask/Django).  \n",
    "✅ **Use Transformers (GPT-3)** for smarter responses.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Run the Chatbot**\n",
    "\n",
    "```bash\n",
    "python chatbot.py\n",
    "```\n",
    "\n",
    "(Ensure `intents.json` is in the same directory.)\n",
    "\n",
    "---\n",
    "\n",
    "## **Final Thoughts**\n",
    "\n",
    "This chatbot:\n",
    "\n",
    "- **Understands user intent** using NLP.\n",
    "- **Remembers context** (e.g., asks for a city after weather query).\n",
    "- **Can be extended** (APIs, voice, web interface).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Chat, reflections\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Define patterns and responses\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.chat.util import Chat, reflections\n",
    "\n",
    "# Define patterns and responses\n",
    "pairs = [\n",
    "    [\n",
    "        r\"hi|hello|hey\",\n",
    "        [\"Hello!\", \"Hi there!\", \"Hey!\"]\n",
    "    ],\n",
    "    [\n",
    "        r\"how are you ?\",\n",
    "        [\"I'm good, how about you?\", \"Doing great! How about yourself?\"]\n",
    "    ],\n",
    "    [\n",
    "        r\"(.*) your name ?\",\n",
    "        [\"I'm a chatbot!\", \"Call me ChatGPT!\"]\n",
    "    ],\n",
    "    [\n",
    "        r\"quit\",\n",
    "        [\"Goodbye!\", \"See you later!\", \"Have a great day!\"]\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Create chatbot\n",
    "chatbot = Chat(pairs, reflections)\n",
    "\n",
    "def chat():\n",
    "    print(\"Hello! I'm your chatbot. Type 'quit' to exit.\")\n",
    "    while True:\n",
    "        user_input = input(\"\")\n",
    "        if user_input.lower() == 'quit':\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        response = chatbot.respond(user_input)\n",
    "        print(response)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chat()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating an advanced chatbot in Python involves several aspects, including natural language processing (NLP), machine learning models, and frameworks for handling conversational logic. A complete Python code for an advanced chatbot would require integrating libraries for NLP, such as **NLTK**, **spaCy**, or using pre-trained models from **Hugging Face's Transformers**.\n",
    "\n",
    "Below is a more advanced Python chatbot that uses a **Transformer-based model** from the Hugging Face library, along with **Flask** for creating a web interface. This chatbot will leverage a pre-trained model for better understanding and generating responses.\n",
    "\n",
    "### **Prerequisites:**\n",
    "\n",
    "1. Install necessary libraries:\n",
    "\n",
    "   ```bash\n",
    "   pip install transformers\n",
    "   pip install torch\n",
    "   pip install flask\n",
    "   ```\n",
    "\n",
    "2. The chatbot will use a pre-trained model from the Hugging Face library. We'll use a model like **DialoGPT** for conversational capabilities.\n",
    "\n",
    "### **Complete Python Code for an Advanced Chatbot:**\n",
    "\n",
    "```python\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "# Load pre-trained model and tokenizer from Hugging Face\n",
    "model_name = \"microsoft/DialoGPT-medium\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Keep track of the conversation history\n",
    "chat_history_ids = None\n",
    "\n",
    "# Helper function to generate responses\n",
    "def generate_response(input_text):\n",
    "    global chat_history_ids\n",
    "\n",
    "    # Tokenize user input and encode it into tensors\n",
    "    new_user_input_ids = tokenizer.encode(input_text + tokenizer.eos_token, return_tensors='pt')\n",
    "\n",
    "    # Append new user input to the history\n",
    "    if chat_history_ids is None:\n",
    "        chat_history_ids = new_user_input_ids\n",
    "    else:\n",
    "        chat_history_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1)\n",
    "\n",
    "    # Generate a response from the model\n",
    "    bot_output_ids = model.generate(chat_history_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id,\n",
    "                                    top_k=50, top_p=0.95, temperature=0.7, no_repeat_ngram_size=3, do_sample=True)\n",
    "\n",
    "    # Decode the bot's response and update the history\n",
    "    chat_history_ids = bot_output_ids\n",
    "    bot_response = tokenizer.decode(bot_output_ids[:, chat_history_ids.shape[-1]:][0], skip_special_tokens=True)\n",
    "\n",
    "    return bot_response\n",
    "\n",
    "# Route to handle chatbot requests via POST method\n",
    "@app.route(\"/chat\", methods=[\"POST\"])\n",
    "def chat():\n",
    "    # Get the user input from the POST request\n",
    "    user_input = request.json.get(\"message\")\n",
    "\n",
    "    if user_input:\n",
    "        # Generate response from the model\n",
    "        bot_response = generate_response(user_input)\n",
    "        return jsonify({\"response\": bot_response})\n",
    "    else:\n",
    "        return jsonify({\"response\": \"Sorry, I didn't understand that.\"})\n",
    "\n",
    "# Main route for testing the chatbot\n",
    "@app.route(\"/\", methods=[\"GET\"])\n",
    "def home():\n",
    "    return \"Chatbot is running. Send a POST request to /chat.\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the Flask app\n",
    "    app.run(debug=True)\n",
    "```\n",
    "\n",
    "### **Explanation of the Code:**\n",
    "\n",
    "1. **Model and Tokenizer Setup**:\n",
    "\n",
    "   - We load the **DialoGPT-medium** model and its tokenizer from the Hugging Face `transformers` library. The tokenizer converts the text input into token IDs that the model can process, and the model generates the response based on the input.\n",
    "   - The `AutoModelForCausalLM` is used for causal language modeling (chatbots and text generation).\n",
    "\n",
    "2. **Conversation History**:\n",
    "\n",
    "   - The `chat_history_ids` variable is used to keep track of the conversation history. This allows the model to generate responses that are contextually aware of previous messages.\n",
    "\n",
    "3. **Flask API Setup**:\n",
    "   - The chatbot runs as a simple Flask web service. You can send a POST request with a message, and the bot will respond.\n",
    "   - The endpoint `/chat` listens for POST requests with JSON data that includes the message from the user.\n",
    "4. **Response Generation**:\n",
    "   - The function `generate_response` processes the user's input, appends it to the conversation history, and then uses the model to generate a response.\n",
    "   - The response is then decoded and returned as a JSON object.\n",
    "\n",
    "### **Running the Chatbot Locally:**\n",
    "\n",
    "1. Save the code above into a Python file (e.g., `chatbot.py`).\n",
    "2. Run the chatbot with:\n",
    "\n",
    "   ```bash\n",
    "   python chatbot.py\n",
    "   ```\n",
    "\n",
    "   This will start a Flask server on `http://127.0.0.1:5000/`.\n",
    "\n",
    "3. Use a REST client like **Postman** or **cURL** to interact with the chatbot by sending POST requests.\n",
    "\n",
    "   Example `cURL` command to chat with the bot:\n",
    "\n",
    "   ```bash\n",
    "   curl -X POST -H \"Content-Type: application/json\" -d '{\"message\": \"Hello, chatbot!\"}' http://127.0.0.1:5000/chat\n",
    "   ```\n",
    "\n",
    "### **Sample Output:**\n",
    "\n",
    "If you send a message like:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"message\": \"Hi, how are you?\"\n",
    "}\n",
    "```\n",
    "\n",
    "The bot might respond with:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"response\": \"Hi! I'm doing great. How can I assist you today?\"\n",
    "}\n",
    "```\n",
    "\n",
    "### **Features and Customization:**\n",
    "\n",
    "- **Memory Management**: The `chat_history_ids` allows the chatbot to remember previous conversations, which makes it more interactive and context-aware.\n",
    "- **Advanced Features**:\n",
    "  - **Multi-turn Conversations**: By tracking `chat_history_ids`, you can enable the bot to handle multi-turn conversations.\n",
    "  - **Temperature, Top-K, and Top-P Sampling**: The model’s response generation can be adjusted by tweaking the parameters like temperature (for randomness), top-k (limiting the candidate words), and top-p (nucleus sampling).\n",
    "\n",
    "### **Conclusion:**\n",
    "\n",
    "This chatbot setup is based on the **DialoGPT-medium** model and provides a simple yet powerful conversational interface. By using Flask, we’ve created a web API that allows you to interact with the chatbot via HTTP requests. You can improve this further by adding features like sentiment analysis, more sophisticated state management, or integrating it with a front-end for a more interactive experience.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
